windows()
plot(x, pch=16, col=(3-y))
dev.off()
dev.off()
par(mfrow=c(1,1))
plot(x, pch=16, col=(3-y))
dat = data.frame(x=x, y=as.factor(y)) # need factors for classification
library(e1071)
install.packages(c("arules", "boot", "BradleyTerry2", "car", "caret", "class", "cluster", "codetools", "colorspace", "corpcor", "e1071", "foreign", "Formula", "gbm", "gdata", "ggplot2", "gridExtra", "gss", "gtools", "httr", "igraph", "installr", "ISwR", "KernSmooth", "lattice", "lme4", "manipulate", "mapproj", "maps", "MASS", "Matrix", "mclust", "mgcv", "mnormt", "mvtnorm", "NbClust", "nlme", "nnet", "party", "partykit", "plotrix", "plyr", "psych", "pwr", "quantmod", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "R6", "Rcpp", "RcppEigen", "RCurl", "rpart", "scales", "spatial", "stringi", "stringr", "survival", "testthat", "tree", "tseries", "TTR", "vcd", "zoo"))
set.seed(1)
x = matrix(rnorm(20*2),ncol=2)
y = c(rep(-1,10), rep(1,10))
x[y==1,] = x[y==1,] + 1
par(mfrow=c(1,1))
plot(x, pch=16, col=(3-y))
dat = data.frame(x=x, y=as.factor(y)) # need factors for classification
library(e1071)
q()
library("e1071", lib.loc="C:/Program Files/R/R-3.1.2/library")
set.seed(1)
x = matrix(rnorm(20*2),ncol=2)
y = c(rep(-1,10), rep(1,10))
x[y==1,] = x[y==1,] + 1
par(mfrow=c(1,1))
plot(x, pch=16, col=(3-y))
dat = data.frame(x=x, y=as.factor(y)) # need factors for classification
library(e1071)
svmfit = svm(y~., data=dat, kernel="linear", cost=10, scale=FALSE)
plot(svmfit, dat)
dat
svmfit$index
svmfit
summary(svmfit)
svmfit = svm(y~.,data=dat,kernel="linear",cost=0.1,scale=FALSE)
plot(svmfit, dat)
svmfit$index
set.seed(1)
tune.out = tune(svm, y~.,data=dat,kernel="linear",
ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
summary(tune.out)
bestmod = tune.out$best.model
summary(bestmod)
xtest = matrix(rnorm(20*2), ncol=2)
ytest = sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,] = xtest[ytest==1,] + 1
testdat = data.frame(x=xtest,y=as.factor(ytest))
ypred = predict(bestmod,testdat)
table(predict=ypred, truth=testdat$y)
svmfit = svm(y~., data=dat, kernel="linear", cost=0.01,
scale=FALSE)
ypred = predict(svmfit, testdat)
table(predict=ypred, truth=testdat$y)
x[y==1,] = x[y==1,] + 0.5
plot(x, col=(y+5)/2, pch=19)
dat = data.frame(x=x,y=as.factor(y))
svmfit = svm(y~.,data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
svmfit = svm(y~.,data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit,dat)
set.seed(1)
x = matrix(rnorm(200*2), ncol=2)
x[1:100,] = x[1:100,] + 2
x[101:150,] = x[101:150,] - 2
y = c(rep(1,150),rep(2,50))
dat = data.frame(x=x, y=as.factor(y))
plot(x,col=y)
plot(x,col=y, pch=16)
train = sample(200,100)
train
svmfit = svm(y~., data=dat[train,], kernel="radial",
gamma=1, cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit = svm(y~., data=dat[train,], kernel="radial", gamma=1,
cost=1e5)
plot(svmfit,dat[train,])
set.seed(1)
tune.out = tune(svm, y~., data=dat[train,], kernel="radial",
ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4)))
summary(tune.out)
testData = dat[-train,"y"]
testPred = predict(tune.out$best.model, newx=dat[-train,])
table(testData, testPred)
testData
dat
dat[,3]
library(ROCR)
rocplot=function(pred,truth, ...){
predob = prediction(pred,truth)
perf= performance(predob, "tpr", "fpr")
plot(perf,...)}
svmfit.opt = svm(y~.,data=dat[train,], kernel="radial",
gamma=2,cost=1,decision.values=T)
fitted = attributes(predict(svmfit.opt,dat[train,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],add=T,col="red")
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],add=T,col="red")
svmfit.flex = svm(y~., data=dat[train,],kernel="radial",
gamma=50,cost=1, decision.values=T)
fitted = attributes(predict(svmfit.flex,dat[train,],decision.values=T))$decision.values
rocplot(fitted,dat[train,"y"],add=T,col="red")
windows()
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],add=T,col="red")
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],add=T,col="red")
set.seed(1)
x = rbind(x, matrix(rnorm(50*2), ncol=2))
y = c(y, rep(0,50))
x[y==0,2] = x[y==0,2] + 2
dat = data.frame(x=x,y=as.factor(y))
par(mfrow=c(1,1))
plot(x, col=(y+1))
plot(x, col=(y+1), pch=16)
svmfit = svm(y~.,data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit,dat)
library(ROCR)
rocplot=function(pred,truth, ...){
predob = prediction(pred,truth)
perf= performance(predob, "tpr", "fpr")
plot(perf,truth,...)}
svmfit.opt = svm(y~.,data=dat[train,], kernel="radial",
gamma=2,cost=1,decision.values=T)
fitted = attributes(predict(svmfit.opt,dat[train,],
decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],add=T,col="red")
library(ISLR)
names(Khan)
library(ISLR)
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
dat = data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out = svm(y~.,data=dat, kernel="linear", cost=10)
summary(out)
table(out$fitted, dat$y)
dat.test = data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred.test = predict(out, newdata=dat.test)
table(pred.test, dat.test$y)
q()
library(ISLR)
set.seed(1)
train = sample(392, 196)
lm.fit = lm(mpg~horsepower, data=Auto, subset=train)
attach(Auto)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2), data=Auto, subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3 = lm(mpg~poly(horsepower,3), data=Auto, subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
set.seed(2)
train = sample(392,196)
lm.fit = lm(mpg~horsepower, data=Auto, subset=train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2), data=Auto, subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3 = lm(mpg~poly(horsepower,3), data=Auto, subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
glm.fit = glm(mpg ~ horsepower, data=Auto)
coef(glm.fit)
lm.fit = lm(mpg~horsepower, data=Auto)
coef(lm.fit)
library(boot)
glm.fit = glm(mpg~horsepower, data=Auto)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta
cv.error = rep(0,5)
for (i in 1:5){
glm.fit = glm(mpg~poly(horsepower,i), data=Auto)
cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error = rep(0,5)
for (i in 1:5){
glm.fit = glm(mpg~poly(horsepower,i), data=Auto)
cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 = rep(0,10)
for (i in 1:10){
glm.fit = glm(mpg~poly(horsepower,1),data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error.10
alpha.fn = function(data,index){
X = data$X[index]
Y = data$Y[index]
return ( (var(Y)-cov(X,Y)) / (var(X)+var(Y)-2*cov(X,Y)) )
}
alpha.fn(Portfolio, 1:100)
set.seed(1)
alpha.fn(Portfolio,sample(100,100,replace=T))
boot(Portfolio,alpha.fn, R=1000)
boot.fn = function(data,index){
return ( coef(lm(mpg~horsepower, data=data, subset=index)))
boot.fn(Auto,1:392)
}
boot.fn = function(data,index){
return ( coef(lm(mpg~horsepower, data=data, subset=index)))
}
boot.fn(Auto,1:392)
set.seed(1)
boot.fn(Auto,sample(392,392,replace=T))
boot.fn(Auto,sample(392,392,replace=T))
boot(Auto,boot.fn,1000)
summary(lm(mpg~horsepower,data=Auto))$coef
boot.fn = function(data,index){
coefficients(lm(mpg~horsepower+I(horsepower^2),
data=data, subset=index))
}
set.seed(1)
boot(Auto,boot.fn,1000)
summary(lm(mpg~horsepower+I(horsepower^2), data=Auto))$coef
q()
getwd()
library("ISLR", lib.loc="C:/Program Files/R/R-3.1.2/library")
q()
library(e1071)
train.indices = sample(1:nrow(iris),100)
iris.train = iris[train.indices,]
iris.test = iris[-train.indices,]
model = svm(Species ~ ., data=iris.train)
results = predict(object=model, newdata=iris.test,type="class")
table(results, iris.test$Species)
library(arules)
data("Adult")
rules = apriori(Adult,
parameter=list(support=0.4,confidence=0.7),
appearance=list(rhs=c("race=White","sex=Male"),default="lhs"))
rules.sorted = sort(rules,by="lift")
top5.rules = head(rules.sorted,5)
as(top5.rules,"data.frame")
library(mclust)
# Train model
model = Mclust(subset(iris,select=-Species))
# Evaluate with confusion matrix
table(model$classification, iris$Species)
# Plot the model
plot(model)
library(igraph)
library(dplyr)
g = random.graph.game(n=10,p.or.m=1/4,directed=TRUE)
plot(g)
pr = page.rank(g)$vector
# View the PageRanks
df = data.frame(Object=1:10, PageRank=pr)
arrange(df, desc(PageRank))
library(adabag)
train.indices = sample(1:nrow(iris),100)
iris.train = iris[train.indices,]
iris.test = iris[-train.indices,]
model = boosting(Species ~ ., data=iris.train)
results = predict(object=model, newdata=iris.test, type="class")
results$confusion
library(e1071)
train.indices = sample(1:nrow(iris),100)
iris.train = iris[train.indices,]
iris.test = iris[-train.indices,]
model = naiveBayes(x=subset(iris.train,select=-Species),
y=iris.train$Species)
results = predict(object=model,newdata=iris.test,type="class")
table(results,iris.test$Species)
library(rpart)
train.indices = sample(1:nrow(iris),100)
iris.train = iris[train.indices,]
iris.test = iris[-train.indices,]
model = rpart(Species ~., data=iris.train)
results = predict(object=model, newdata=iris.test, type="class")
table(results, iris.test$Species)
q()
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket)
cor(Smarket[,-9])
cor(Smarket[,-"Direction"])
cor(Smarket[,-9])
cor(Smarket[,-c("Direction")])
plot(Smarket$Volume)
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
summary(glm.fit)$coef[,4]
glm.probs = predict(glm.fit, type="response")
glm.probs[1:10]
contrasts(Smarket$Direction)
dim(Smarket)
dim(Smarket)[1]
dim(Smarket)[2]
dim(Smarket)
a = dim(Smarket)
a
[r,c] = dim(Smarket)
d = dim(Smarket)
glm.pred = rep("Down", d[1])
glm.pred[glm.probs>0.5] = "Up"
table(glm.pred, Smarket$Direction)
index = which(glm.pred="Down" & Smarket$Direction=="Down")
index = which(glm.pred=="Down" & Smarket$Direction=="Down")
length(index)
indexUpUp = which(glm.pred=="Up" & Smarket$Direction=="Up")
length(indexUpUp)
performance = (length(indexDownDown)+length(indexUpUp))/d[1]
indexDownDown = which(glm.pred=="Down" & Smarket$Direction=="Down")
performance = (length(indexDownDown)+length(indexUpUp))/d[1]
performance
mean(glm.pred==Smarket$Direction)
train = (Smarket$Year<2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005 = Smarket$Direction[!train]
glm.fit = glm(Direction ~ Lag1+Lag2+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial,subset=train)
glm.probs = predict(glm.fit,Smarket.2005,type="response")
glm.pred = rep("Down", 252)
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
indexDownDown = which(glm.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(glm.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/d[1]
performance
d = dim(Direction.2005)
d
d = length(Direction.2005)
d
nObs = length(Direction.2005)
indexDownDown = which(glm.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(glm.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
glm.fit = glm(Direction~Lag1+Lag2,data=Smarket,family=binomial, subset=train)
glm.probs = predict(glm.fit, Smarket.2005,type="response")
nObs = length(Direction.2005)
glm.pred = rep("Down", nObs)
glm.pred[glm.probs>0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred==Direction.2005)
indexDownDown = which(glm.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(glm.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
predict(glm.fit,newdata=data.frame(Lag1=c(1.2,1.5),
Lag2=c(1.1,-0.8)),type="response")
library(MASS)
train = (Smarket$Year<2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005 = Smarket$Direction[!train]
lda.fit = lda(Direction~Lag1+Lag2,data=Smarket,subset=train)
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit, Smarket.2005)
names(lda.pred)
lda.class = lda.pred$class
table(lda.class,Direction.2005)
sum(lda.pred$posterior[,1]>=0.5)
sum(lda.pred$posterior[,1]<0.5)
lda.pred$posterior[1:20,1]
lda.class[1:20]
sum(lda.pred$posterior[,1]>0.9)
library(MASS)
train = (Smarket$Year<2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005 = Smarket$Direction[!train]
qda.fit = qda(Direction~Lag1+Lag2,data=Smarket,subset=train)
ada.fit
qda.fit
plot(lda.fit)
qda.class = predict(qda.fit, Smarket.2005)$class
# Performance is almost the same as Logistic regression
table(qda.class,Direction.2005)
mean(lda.class==Direction.2005)
(30+121)/(30+20+81+121)
mean(qda.class==Direction.2005)
library(class)
train.X = cbind(Smarket$Lag1,Smarket$Lag2)[train,]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction,k=1)
train.X = cbind(Smarket$Lag1,Smarket$Lag2)[train,]
test.X = cbind(Smarket$Lag1,Smarket$Lag2)[!train,]
train.Direction = Smarket$Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction,k=1)
table(knn.red, Direction.2005)
table(knn.pred, Direction.2005)
nObs = length(Direction.2005)
indexDownDown = which(glm.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(glm.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
nObs = length(Direction.2005)
indexDownDown = which(knn.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(knn.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
knn.pred = knn(train.X, test.X, train.Direction,k=3)
table(knn.pred, Direction.2005)
nObs = length(Direction.2005)
indexDownDown = which(knn.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(knn.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction,k=3)
table(knn.pred, Direction.2005)
nObs = length(Direction.2005)
indexDownDown = which(knn.pred=="Down" & Direction.2005=="Down")
indexUpUp = which(knn.pred=="Up" & Direction.2005=="Up")
performance = (length(indexDownDown)+length(indexUpUp))/nObs
performance
library(ISLR)
dim(Caravan)
summary(Caravan$Purchase)
length( which(Caravan$Purchase == "Yes") )
length( which(Caravan$Purchase == "Yes") ) / length(Caravan$Purchase)
stand.X = scale(Caravan[,-86]) # column 86 has purchase
var(Caravan[,1])
var(Caravan[,2])
var(stand.X[,1])
var(stand.X[,2])
test = 1:1000
train.X = stand.X[-test,]
test.X = stand.X[test,]
train.Y = Caravan$Purchase[-test]
test.Y = Caravan$Purchase[test]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Y, k=1)
mean(test.Y != knn.pred)
mean(test.Y != "No")
table(knn.pred, test.Y)
indYN = which(knn.pred=="Yes" & test.Y == "No")
indYY = which(knn.pred=="Yes" & test.Y == "Yes")
performance = length(indYY) / (length(indYn)+length(indYY))
performance = length(indYY) / (length(indYN)+length(indYY))
performance
knn.pred = knn(train.X, test.X, train.Y, k=3)
table(knn.pred, test.Y)
indYN = which(knn.pred=="Yes" & test.Y == "No")
indYY = which(knn.pred=="Yes" & test.Y == "Yes")
performance = length(indYY) / (length(indYN)+length(indYY))
performance
knn.pred = knn(train.X, test.X, train.Y, k=5)
table(knn.pred, test.Y)
indYN = which(knn.pred=="Yes" & test.Y == "No")
indYY = which(knn.pred=="Yes" & test.Y == "Yes")
performance = length(indYY) / (length(indYN)+length(indYY))
performance
glm.fit = glm(Purchase~.,data=Caravan,family=binomial,
subset=-test)
glm.probs = predict(glm.fit, Caravan[test,],type="response")
glm.pred = rep("No",1000)
glm.pred[glm.probs>0.5] = "Yes"
table(glm.pred, test.Y)
indYN = which(glm.pred=="Yes" & test.Y == "No")
indYY = which(glm.pred=="Yes" & test.Y == "Yes")
performance = length(indYY) / (length(indYN)+length(indYY))
performance
glm.pred = rep("No",1000)
glm.pred[glm.probs>0.25] = "Yes"
table(glm.pred, test.Y)
indYN = which(glm.pred=="Yes" & test.Y == "No")
indYY = which(glm.pred=="Yes" & test.Y == "Yes")
performance = length(indYY) / (length(indYN)+length(indYY))
performance
q()
existing_cases_file = 'tb_existing_100.csv'
existing_df = read.csv(text=existing_cases_file,row.names=1,stringsAsFactors=F)
str(existing_df)
setwd("~/")
existing_df = read.csv(text=existing_cases_file,row.names=1,stringsAsFactors=F)
str(existing_df)
ls()
dir()
setwd("C:/Users/craig/OneDrive/RPmisc")
existing_cases_file = 'tb_existing_100.csv'
existing_df = read.csv(text=existing_cases_file,row.names=1,stringsAsFactors=F)
str(existing_df)
getwd()
dir()
existing_df = read.csv(existing_cases_file,row.names=1,stringsAsFactors=F)
str(existing_df)
existing_df[c(1,2,3,4,5,6,15,16,17,18)]
existing_df[c(1,2,3,4,5,6,15,16,17,18)] =
lapply(existing_df[c(1,2,3,4,5,6,15,16,17,18)],
function(x) {as.integer(gsub(',','',x))})
str(existing_df)
head(existing_df)
nrow(existing_df)
ncol(existing_df)
existing_df_t = existing_df
existing_df = as.data.frame(t(existing_df))
head(existing_df,3)
rownames(existing_df)
colnames(existing_df)
existing_df[,1]
q()
q()
